{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effects of weather and price on Yelp star rating\n",
    "\n",
    "It may be a good idea to segregate the data by business type (restaurant, hardware store, etc.). It could be easier and less computationally intensive per category. But it would be interesting to find very general features that can help determine star ratings for all businesses.\n",
    "\n",
    "Three stages: first we look at comment text alone, to see how accurate we can predict star rating based on that. Then we add in weather effects. Finally, we consider the relative price of the business being reviewed. Since star ratings are highly subjective, users may be influenced by many things when it comes to the rating. These factors will undoubtedly affect the review text as well, but there may also be subtle additional effects on the star rating.\n",
    "\n",
    "The test will be done in a rather crude way: if including weather and price can improve the accuracy of star predictions, then we will conclude that weather and price have an effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keith/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (Dense, Dropout, Input, LSTM, Activation, Flatten,\n",
    "                          Convolution1D, MaxPooling1D, Bidirectional,\n",
    "                         GlobalMaxPooling1D, Embedding, BatchNormalization,\n",
    "                         SpatialDropout1D)\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score, auc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH = \"/d/data/yelpdata/dataset/\"\n",
    "WEAT = f'{PATH}processed_weather/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#businesses = pd.read_csv(f'{PATH}business_on.csv', index_col=0)\n",
    "reviews = pd.read_csv(f'{PATH}review_on.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = reviews[['stars','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews['text'].fillna('empty', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 1: Predicting star rating based on review text alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_up(t):\n",
    "    t = t.strip().lower()\n",
    "    words = t.split()\n",
    "    \n",
    "    # first get rid of the stopwords, or a lemmatized stopword might not\n",
    "    # be recognized as a stopword\n",
    "    \n",
    "    imp_words = ' '.join(w for w in words if w not in set(stopwords.words('english')))\n",
    "\n",
    "    # lemmatize based on adjectives (J), verbs (V), nouns (N) and adverbs (R) to\n",
    "    # return only the base words (as opposed to stemming which can return\n",
    "    # non-words). e.g. ponies -> poni with stemming, and pony with lemmatizing\n",
    "    \n",
    "    final_words = ''\n",
    "    \n",
    "    lemma = WordNetLemmatizer()\n",
    "    for (w,tag) in pos_tag(word_tokenize(imp_words)):\n",
    "        if tag.startswith('J'):\n",
    "            final_words += ' '+ lemma.lemmatize(w, pos='a')\n",
    "        elif tag.startswith('V'):\n",
    "            final_words += ' '+ lemma.lemmatize(w, pos='v')\n",
    "        elif tag.startswith('N'):\n",
    "            final_words += ' '+ lemma.lemmatize(w, pos='n')\n",
    "        elif tag.startswith('R'):\n",
    "            final_words += ' '+ lemma.lemmatize(w, pos='r')\n",
    "        else:\n",
    "            final_words += ' '+ w\n",
    "    \n",
    "    return final_words\n",
    "\n",
    "# what a great name. do_stuff\n",
    "\n",
    "def do_stuff (df):\n",
    "    text = df['text'].copy()\n",
    "    \n",
    "    text.replace(to_replace={r'[^\\x00-\\x7F]':' '},inplace=True,regex=True)\n",
    "    text.replace(to_replace={r'[^a-zA-Z]': ' '},inplace=True,regex=True)\n",
    "    \n",
    "    # Then lower case, tokenize and lemmatize\n",
    "\n",
    "    # with over 600,000 entries, this is going to be one hell of a long apply...\n",
    "    \n",
    "    text = text.apply(lambda t:clean_up(t))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seq_model (X_train, y_train, test, val='no'):\n",
    "    model=Sequential()\n",
    "    model.add(Embedding(50000,128,input_length=1000))\n",
    "    model.add(SpatialDropout1D(0.25))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(5,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    \n",
    "    if val == 'no':\n",
    "        model.fit(X_train,y_train,batch_size=512,epochs=5)\n",
    "    else:\n",
    "        model.fit(X_train,y_train,batch_size=512,epochs=5,validation_split=0.2)\n",
    "    pred = model.predict(test)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data = do_stuff(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data.to_csv(f'{PATH}review_on_processed_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.Series.from_csv(f'{PATH}review_on_processed_text.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stars = reviews['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enc = LabelEncoder()\n",
    "enc.fit(stars)\n",
    "y = enc.transform(stars)\n",
    "dummy_y = np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.fillna('empty', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tok = Tokenizer(num_words=50000)\n",
    "tok.fit_on_texts(data)\n",
    "     \n",
    "# set our max text length to 1000 characters, some of these reviews are pretty long\n",
    "sequenced = tok.texts_to_sequences(data)\n",
    "padded = pad_sequences(sequenced,maxlen=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(padded, dummy_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 405993 samples, validate on 101499 samples\n",
      "Epoch 1/5\n",
      "405993/405993 [==============================] - 167s 410us/step - loss: 1.1782 - acc: 0.4873 - val_loss: 0.9467 - val_acc: 0.5836\n",
      "Epoch 2/5\n",
      "405993/405993 [==============================] - 167s 412us/step - loss: 0.9983 - acc: 0.5599 - val_loss: 0.9301 - val_acc: 0.5899\n",
      "Epoch 3/5\n",
      "405993/405993 [==============================] - 171s 421us/step - loss: 0.9626 - acc: 0.5768 - val_loss: 0.9254 - val_acc: 0.5902\n",
      "Epoch 4/5\n",
      "405993/405993 [==============================] - 167s 411us/step - loss: 0.9377 - acc: 0.5897 - val_loss: 0.9231 - val_acc: 0.5919\n",
      "Epoch 5/5\n",
      "405993/405993 [==============================] - 166s 408us/step - loss: 0.9152 - acc: 0.6017 - val_loss: 0.9251 - val_acc: 0.5904\n"
     ]
    }
   ],
   "source": [
    "pred = seq_model (X_train, y_train, X_test, val='yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.869052128035148"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.argmax(pred, axis=1)\n",
    "ys = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add 1 to each row label to get the star rating..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.75      0.73     15271\n",
      "          1       0.46      0.33      0.39     13079\n",
      "          2       0.49      0.43      0.46     22067\n",
      "          3       0.54      0.61      0.57     39122\n",
      "          4       0.69      0.69      0.69     37335\n",
      "\n",
      "avg / total       0.59      0.59      0.59    126874\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ys,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11481,  2240,   814,   392,   344],\n",
       "       [ 3102,  4340,  4006,  1306,   325],\n",
       "       [  809,  2242,  9502,  8468,  1046],\n",
       "       [  348,   417,  4318, 23950, 10089],\n",
       "       [  316,    98,   623, 10619, 25679]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix (ys, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While 0.59 precision isn't great, the 0.869 AUC score is actually very very okay, one of the better kinds of okay. Also, the validation scores during training were very good, which is always helpful. A benefit, no doubt, of using all 630,000 reviews of business in the Toronto area.\n",
    "\n",
    "We can see why the AUC is pretty good: the vast majority of predicted scores are within 1 star of the actual rating. Additionally, 1 and 5 star ratings had the greatest precision and recall, so our model is decent at picking up extreme sentiment (or the users are effusive in praise and unrestrained in condemnation).\n",
    "\n",
    "But let's see if adding in weather and relative price can increase accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2: weather effects\n",
    "\n",
    "Star ratings are neither objective nor scientific. We humans often make  bizarre, irrational and otherwise inconsistent choices due to many internal and external factors. Let's consider weather as one of the external factors, especially with regards to giving a star rating for a business. While good weather and a good mood might influence me to leave a more positive review as well as a higher star rating, there is really no way know the sort of review I would have left had the weather been different.\n",
    "\n",
    "What we can do is see if the review text matches with the score, and if knowing the weather conditions can improve the accuracy of our star predictions.\n",
    "\n",
    "This raises an interesting question for businesses, since weather is something entirely out of their control. But it does suggest that if a business' sales are clearly affected by its star ratings, perhaps something extra can be done to improve customer satisfaction on a rainy day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_w = pd.read_csv(f'{PATH}review_on.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_w = reviews_w[['stars','date','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keith/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (12,16,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "weather = pd.read_csv(f'{WEAT}all_weather.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Time</th>\n",
       "      <th>Data Quality</th>\n",
       "      <th>Temp (°C)</th>\n",
       "      <th>Temp Flag</th>\n",
       "      <th>Dew Point Temp (°C)</th>\n",
       "      <th>Dew Point Temp Flag</th>\n",
       "      <th>...</th>\n",
       "      <th>Wind Spd Flag</th>\n",
       "      <th>Visibility (km)</th>\n",
       "      <th>Visibility Flag</th>\n",
       "      <th>Stn Press (kPa)</th>\n",
       "      <th>Stn Press Flag</th>\n",
       "      <th>Hmdx</th>\n",
       "      <th>Hmdx Flag</th>\n",
       "      <th>Wind Chill</th>\n",
       "      <th>Wind Chill Flag</th>\n",
       "      <th>Weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>2006-01-01 00:00</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>2006-01-01 01:00</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>01:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>2006-01-01 02:00</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>02:00</td>\n",
       "      <td></td>\n",
       "      <td>-4.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>2006-01-01 03:00</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>03:00</td>\n",
       "      <td></td>\n",
       "      <td>-4.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Freezing Drizzle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>2006-01-01 04:00</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>04:00</td>\n",
       "      <td></td>\n",
       "      <td>-4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date/Time    Year  Month  Day   Time Data Quality  Temp (°C)  \\\n",
       "0.0  2006-01-01 00:00  2006.0    1.0  1.0  00:00          NaN        NaN   \n",
       "1.0  2006-01-01 01:00  2006.0    1.0  1.0  01:00          NaN        NaN   \n",
       "2.0  2006-01-01 02:00  2006.0    1.0  1.0  02:00                    -4.2   \n",
       "3.0  2006-01-01 03:00  2006.0    1.0  1.0  03:00                    -4.5   \n",
       "4.0  2006-01-01 04:00  2006.0    1.0  1.0  04:00                    -4.0   \n",
       "\n",
       "    Temp Flag  Dew Point Temp (°C) Dew Point Temp Flag        ...         \\\n",
       "0.0       NaN                  NaN                 NaN        ...          \n",
       "1.0       NaN                  NaN                 NaN        ...          \n",
       "2.0       NaN                 -5.6                 NaN        ...          \n",
       "3.0       NaN                 -5.6                 NaN        ...          \n",
       "4.0       NaN                 -5.2                 NaN        ...          \n",
       "\n",
       "     Wind Spd Flag Visibility (km)  Visibility Flag Stn Press (kPa)  \\\n",
       "0.0            NaN             NaN              NaN             NaN   \n",
       "1.0            NaN             NaN              NaN             NaN   \n",
       "2.0            NaN             3.2              NaN          100.20   \n",
       "3.0            NaN             2.3              NaN          100.27   \n",
       "4.0            NaN             6.4              NaN          100.27   \n",
       "\n",
       "     Stn Press Flag Hmdx  Hmdx Flag Wind Chill  Wind Chill Flag  \\\n",
       "0.0             NaN  NaN        NaN        NaN              NaN   \n",
       "1.0             NaN  NaN        NaN        NaN              NaN   \n",
       "2.0             NaN  NaN        NaN       -8.0              NaN   \n",
       "3.0             NaN  NaN        NaN      -10.0              NaN   \n",
       "4.0             NaN  NaN        NaN       -8.0              NaN   \n",
       "\n",
       "              Weather  \n",
       "0.0               NaN  \n",
       "1.0               NaN  \n",
       "2.0              Snow  \n",
       "3.0  Freezing Drizzle  \n",
       "4.0               NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['Year'] = weather['Year'].astype(int)\n",
    "weather['Month'] = weather['Month'].astype(int)\n",
    "weather['Day'] = weather['Day'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_w['date'] = pd.to_datetime(reviews_w['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2012-05-11</td>\n",
       "      <td>Who would have guess that you would be able to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-10-27</td>\n",
       "      <td>Always drove past this coffee house and wonder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-02-09</td>\n",
       "      <td>Not bad!! Love that there is a gluten-free, ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2016-04-06</td>\n",
       "      <td>Love this place!  Peggy is great with dogs and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>This is currently my parents new favourite res...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars       date                                               text\n",
       "0      4 2012-05-11  Who would have guess that you would be able to...\n",
       "1      4 2015-10-27  Always drove past this coffee house and wonder...\n",
       "2      3 2013-02-09  Not bad!! Love that there is a gluten-free, ve...\n",
       "3      5 2016-04-06  Love this place!  Peggy is great with dogs and...\n",
       "4      4 2013-05-01  This is currently my parents new favourite res..."
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_w.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to be continued..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
